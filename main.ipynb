{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (19.3.1)\r\n"
     ]
    }
   ],
   "source": [
    "# instalar paquetes\n",
    "!pip install --upgrade pip && pip install numpy pandas plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar librerías\n",
    "from randomforest import RandomForestModel\n",
    "from randomforest.preprocess import load_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo y datos|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear el modelo\n",
    "model = RandomForestModel()\n",
    "\n",
    "# definir las funciones pedidas\n",
    "fit = model.fit\n",
    "predict = model.predict\n",
    "assert_predictions = model.assert_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar y limpiar (preprocesar) los datasets\n",
    "data_train, data_test = load_dfs('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenar el modelo\n",
    "fit(data=data_train, target='Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = model.forest[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# como visualización interactiva\n",
    "fig = tree.generate_treemap()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en texto plano\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación y testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# revisar qué tan bien nos fue\n",
    "print(assert_predictions(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predecir algo\n",
    "data = next(data_test.iterrows())[1]\n",
    "print(f'DATA:\\n{data};\\n\\nPREDICTION: {predict(data=data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicación y análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos\n",
    "\n",
    "Los _sets_ de entremiento (`data_train`) y de _test_ (`data_test`) son obtenidos como resultado una división aleatoria disjunta de los datos ejecutada por la función `load_dfs`, correspondientes a un 80 y un 20%, respectivamente. Todos los registros con datos nulos son descartados.\n",
    "\n",
    "### Modelos\n",
    "\n",
    "`RandomForestModel` es un modelo de _random forest_. Este almacena los árboles en la variable de instancia `forest`. Cada árbol es modelado a través de `DecisionTreeModel`, que trabaja de manera recursiva. Todos los métodos de estas clases relacionados con la implementación del algoritmo se encuentran documentados en el código fuente contenido en el directorio `randomforest/`.\n",
    "\n",
    "### Entrenamiento\n",
    "\n",
    "El modelo de _random forest_ instanciado en este archivo fue entrenado a través de la función `fit` con 5 árboles de decisión (`n_estimators`). La profundidad máxima de cada árbol es de 4 niveles (`max_depth`) y estos poseen una cantidad mínima de 1000 muestras por nodo para realizar el _split_ (`min_samples_split`).\n",
    "\n",
    "Cada árbol fue entrenado con una muestra aleatoria distinta no disjunta del _set_ de entrenamiento que contiene, aproximadamente, un 20% de sus registros/filas y un 30% de sus atributos/columnas, excluyento el _target_ (`frac_shape`).\n",
    "\n",
    "### Predicciones\n",
    "\n",
    "El modelo realiza predicciones de manera recursiva en cada uno de sus árboles a través de la función `predict`. Luego, retorna la respuesta \"más votada\" (i.e. la moda).\n",
    "\n",
    "La métrica de evaluación calculada por la función `assert_predictions` corresponde al porcentaje de predicciones correcamente realizadas. Esta función recibe un `DataFrame` con el _set_ de _test_ y realiza una predicción por cada entrada, luego compara dicha predicción con la clase del _target_ real y entrega el porcentaje de correctitud.\n",
    "\n",
    "El resultado obtenido para estos parámetros varía entre un 80 y un 90%. Uno esperaría que al aumentar `n_estimators` este número mejore. Por otro lado, aumentar `max_depth` sería positivo hasta cierto punto, pues una gran profundidad puede también llevar al _overfitting_ (sobreajuste).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
